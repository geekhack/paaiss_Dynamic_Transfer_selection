{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SciPy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from SciPy) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import statistics as stats\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 as resnet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 as inception\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 as vgg16\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 as densenet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, losses, optimizers\n",
    "from tensorflow.keras.layers import Dense,Dropout,GlobalAveragePooling2D,Flatten\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n",
    "x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n",
    "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "x_train = tf.repeat(x_train, 3, axis=3)\n",
    "x_test = tf.repeat(x_test, 3, axis=3)\n",
    "x_val = x_train[-2000:,:,:]\n",
    "y_val = y_train[-2000:]\n",
    "x_train = x_train[:-2000,:,:]\n",
    "y_train = y_train[:-2000]\n",
    "\n",
    "y_train = tf.one_hot(y_train.astype(np.int32), depth=100)\n",
    "y_test = tf.one_hot(y_test.astype(np.int32), depth=100)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 Layer prob: 0.47680588709948557\n",
      "154 Layer prob: 0.4755090552320906\n",
      "155 Layer prob: 0.4753669716888586\n",
      "165 Layer prob: 0.47511162689235614\n",
      "168 Layer prob: 0.4744336452623567\n",
      "171 Layer prob: 0.47444871713506\n",
      "172 Layer prob: 0.47388908217501385\n",
      "177 Layer prob: 0.4735913680137435\n",
      "178 Layer prob: 0.4727567811364222\n",
      "184 Layer prob: 0.47304791609964514\n",
      "185 Layer prob: 0.472851803912614\n",
      "186 Layer prob: 0.4719519949944997\n",
      "187 Layer prob: 0.47187031497469206\n",
      "197 Layer prob: 0.4718245858768004\n",
      "200 Layer prob: 0.4714651132618618\n",
      "203 Layer prob: 0.47135721162832145\n",
      "204 Layer prob: 0.4705969971401335\n",
      "209 Layer prob: 0.47024238688476644\n",
      "210 Layer prob: 0.469800143362268\n",
      "216 Layer prob: 0.4697017729729312\n",
      "217 Layer prob: 0.46864275933508914\n",
      "218 Layer prob: 0.4671214002843771\n",
      "219 Layer prob: 0.46694459843702496\n",
      "229 Layer prob: 0.46641793014148336\n",
      "232 Layer prob: 0.46591301789117484\n",
      "235 Layer prob: 0.46517157894736844\n",
      "236 Layer prob: 0.4649891043782527\n",
      "241 Layer prob: 0.46215258488791783\n",
      "242 Layer prob: 0.4617803010941498\n",
      "249 Layer prob: 0.46197811313326126\n",
      "252 Layer prob: 0.4620544316650586\n",
      "253 Layer prob: 0.461346351608083\n",
      "258 Layer prob: 0.4602571103194534\n",
      "259 Layer prob: 0.4596465340496358\n",
      "260 Layer prob: 0.4580739698237745\n",
      "261 Layer prob: 0.4570128229974848\n",
      "263 Layer prob: 0.4572002883816008\n",
      "268 Layer prob: 0.4573571328722703\n",
      "280 Layer prob: 0.4562105744371977\n",
      "283 Layer prob: 0.45494000506189314\n",
      "284 Layer prob: 0.4488047063426737\n",
      "289 Layer prob: 0.44745006259465586\n",
      "290 Layer prob: 0.44621331786981255\n",
      "291 Layer prob: 0.4449080739215107\n",
      "292 Layer prob: 0.44375009660641\n",
      "294 Layer prob: 0.44443405537617897\n",
      "299 Layer prob: 0.44489795843306756\n",
      "conv2d_188 True\n",
      "conv2d_194 True\n",
      "conv2d_199 True\n",
      "conv2d_203 True\n",
      "conv2d_206 True\n",
      "mixed10 True\n",
      "mixed10 True\n",
      "mixed10 True\n",
      "mixed10 True\n"
     ]
    }
   ],
   "source": [
    "model_name = inception\n",
    "input_t = (128,128,3)\n",
    "\n",
    "model = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "#others for testing\n",
    "model2 = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "\n",
    "\n",
    "# get the layer index\n",
    "def getLayerIndex(model_i, layer_name):\n",
    "    for pos, layer_g in enumerate(model_i.layers):\n",
    "        if layer_g.name == layer_name:\n",
    "            return pos\n",
    "\n",
    "\n",
    "# get the convolved layers into an array for looping\n",
    "convolved_layers = []\n",
    "\n",
    "for layer in model.layers:\n",
    "\n",
    "    t = np.array(layer.get_weights()).ndim\n",
    "    array = np.array(layer.get_weights())\n",
    "    if (model_name != resnet50) or (model_name != vgg16):\n",
    "        if (len(array) > 0) and (t > 2):\n",
    "            index = getLayerIndex(model, layer.name)\n",
    "            # append the convolved layer\n",
    "            convolved_layers.append(index)\n",
    "            # print(str(len(array)) + \"for:\" + layer.name + \"at index:\" + str(index))\n",
    "    if (model_name == resnet50) or (model_name == vgg16):\n",
    "        if len(array) > 0 and (t != 2):\n",
    "            index = getLayerIndex(model, layer.name)\n",
    "            # append the convolved layer\n",
    "            convolved_layers.append(index)\n",
    "            # print(str(len(array)) + \"for:\" + layer.name + \"at index:\" + str(index))\n",
    "\n",
    "# get the total number of weights in the array\n",
    "total_layer_weights = 0\n",
    "sum_positives = 0\n",
    "sum_negatives = 0\n",
    "\n",
    "# create a dictionary with layer index and positive values identified\n",
    "layer_positives_dict = defaultdict(list)\n",
    "\n",
    "# create a dictionary for storing the layers and their +ve values probabilities\n",
    "layer_probs_dict = defaultdict(list)\n",
    "\n",
    "# list the convolved layers\n",
    "for c_layer in range(len(convolved_layers)):\n",
    "    # then print for each layer\n",
    "    ####print(\"*******START LAYER: \" + str(convolved_layers[c_layer]) + \" **************** \")\n",
    "    ### print(\"Batches:\" + str(len(model.layers[convolved_layers[c_layer]].get_weights()[0])));\n",
    "    ####print(\"Layer output size: \" + str(model.layers[convolved_layers[c_layer]].get_weights()[0].shape))\n",
    "\n",
    "    # create array for array matrices,feature values and convolved values for each layer\n",
    "    layer_array_matrices = []\n",
    "    layer_feature_sums = []\n",
    "    layer_convolved_values_sum = []\n",
    "\n",
    "    # get the arrays matrices(batches) pixel\n",
    "    for i in range(len(model.layers[convolved_layers[c_layer]].get_weights()[0])):\n",
    "        # get the values for each feature\n",
    "        ######print(\"channels(image):\"+str(len(model.layers[convolved_layers[c_layer]].get_weights()[0][i])))\n",
    "        for x in range(len(model.layers[convolved_layers[c_layer]].get_weights()[0][i])):\n",
    "            ####print(\"Convolved image array :\"+str(len(np.array(model.layers[convolved_layers[c_layer]].get_weights()[0][i][x]))))\n",
    "\n",
    "            # return all the values in the convolutional feature\n",
    "            total_array = np.array(model.layers[convolved_layers[c_layer]].get_weights()[0][i][x])\n",
    "            # return all the negative values in the convolutional feature\n",
    "            x2 = np.array(model.layers[convolved_layers[c_layer]].get_weights()[0][i][x]) < 0\n",
    "            for c in range(len(x2)):\n",
    "                ###print(\"all the trues in depth: \" + str(c + 1) + \" are for feature: \" + str(x + 1))\n",
    "                sum_negatives += sum(x2[c])\n",
    "                # print(sum(x2[c]))\n",
    "            # return all the values\n",
    "            for y in range(len(total_array)):\n",
    "                total_layer_weights += len(total_array[y])\n",
    "\n",
    "            x1 = np.array(model.layers[convolved_layers[c_layer]].get_weights()[0][i][x]) > 0\n",
    "            # get the values for each channel\n",
    "            for a in range(len(x1)):\n",
    "                # print(\"Pixel(matrix position): \" + str(a + 1) + \" Feature Map item: \" + str(x + 1)+\" Array: \"+str(i+1)+\" of \"+str(len(model.layers[convolved_layers[c_layer]].get_weights()[0])))\n",
    "                # print(\"+ve image convolved values at position:\" + str(a))\n",
    "                # get the positive values ready to be passed through activation function for feature map\n",
    "                value_pix = sum(x1[a])\n",
    "                # get the positive values\n",
    "                sum_positives += value_pix\n",
    "\n",
    "                ######print(value_pix)\n",
    "    list_sums = []\n",
    "    list_sums.append((str(convolved_layers[c_layer]), sum_positives))\n",
    "    layer_positives_dict.update(list_sums)\n",
    "\n",
    "    # print the probabilities for each layer\n",
    "    layer_pos_prob = sum_positives / total_layer_weights\n",
    "\n",
    "    # create +ves values array\n",
    "    positives_array = []\n",
    "    for key, val in layer_positives_dict.items():\n",
    "        # print(key, \"corresponds to:\",val,\" positive values\")\n",
    "        positives_array.append(val)\n",
    "        ###used with softmax values\n",
    "        # print(key, \"corresponds to:\", float(val))\n",
    "        # positives_array.append(float(val))\n",
    "        ###end of usage with softmax\n",
    "        # create an array of positives and then use the softmax to get their distribution\n",
    "        # probability\n",
    "\n",
    "    # get the softmax values\n",
    "    # p = tf.nn.softmax(positives_array)\n",
    "    # print(p)\n",
    "    list_layer_probs = []\n",
    "    list_layer_probs.append((str(convolved_layers[c_layer]), layer_pos_prob))\n",
    "    layer_probs_dict.update(list_layer_probs)\n",
    "\n",
    "    # loop through the layer_probs_dictionary\n",
    "    #for lyr, val in layer_probs_dict.items():\n",
    "        #print(lyr, \"Layer prob:\", val)\n",
    "\n",
    "# get the median number of layers to ensure the first layers deal with the feature extraction\n",
    "\n",
    "median_layer = stats.median(convolved_layers)\n",
    "\n",
    "# create dictionary for storing selected median layers\n",
    "second_layer_probs_dict = defaultdict(list)\n",
    "# store the new list of layers to be matched with the mean probability\n",
    "second_half_layers = []\n",
    "\n",
    "# store all probabilities for the selected upper half layers\n",
    "second_half_probs = []\n",
    "# loop through the layers and print those layers above the median\n",
    "for lyr, val in layer_probs_dict.items():\n",
    "    # print(lyr, \"Layer prob:\", val)\n",
    "    if int(lyr) > median_layer:\n",
    "        # store the probabilities of the upper half selected convolved layers\n",
    "        print(lyr, \"Layer prob:\", val)\n",
    "        # update the sum of selected layers probabilities\n",
    "        second_half_probs.append(val)\n",
    "        second_half_layers.append((lyr, val))\n",
    "        second_layer_probs_dict.update(second_half_layers)\n",
    "\n",
    "# get the mean of the layers\n",
    "selected_layers_mean = stats.mean(second_half_probs)\n",
    "final_selected_layers = []\n",
    "# now get the final layers list whose value exceed the mean\n",
    "for s_lyr, v in second_layer_probs_dict.items():\n",
    "    # get the probabilities that are lower than the mean probability\n",
    "    if v < selected_layers_mean:\n",
    "        # store the probabilities of the upper half selected convolved layers\n",
    "        final_selected_layers.append(s_lyr)\n",
    "\n",
    "# print(second_half_layers)\n",
    "# print(str(convolved_layers[c_layer]) + \" probability: \" + str(layer_pos_prob))\n",
    "# print(\"*******END LAYER: \" + str(convolved_layers[c_layer]) + \" **************** \")\n",
    "#model.trainable=False\n",
    "# use the selected layers\n",
    "# use the selected layers\n",
    "s_h_layers =[1,54,41,31,21] #higher kullback\n",
    "s_l_layers =[108,154,241,121] #lower kullback\n",
    "for sb_layer in model.layers:\n",
    "    # sb_layer.trainable = False\n",
    "    index = getLayerIndex(model, sb_layer.name)\n",
    "    #for b in final_selected_layers:\n",
    "    for b in s_h_layers:\n",
    "        if b == index:\n",
    "            sb_layer.trainable = True\n",
    "            #print(str(sb_layer.name) + \" and index is\" + str(b))\n",
    "            print(sb_layer.name,sb_layer.trainable)\n",
    "            \n",
    "# for model 2\n",
    "for sbs_layer in model2.layers:\n",
    "    # sb_layer.trainable = False\n",
    "    index = getLayerIndex(model2, sbs_layer.name)\n",
    "    #for b in final_selected_layers:\n",
    "    for b in s_l_layers:\n",
    "        if b == index:\n",
    "            sb_layer.trainable = True\n",
    "            #print(str(sb_layer.name) + \" and index is\" + str(b))\n",
    "            print(sb_layer.name,sb_layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Functional)    (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 22,116,356\n",
      "Trainable params: 22,081,924\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "upsamp1 = tf.keras.layers.UpSampling2D((2,2))(inputs)\n",
    "upsamp2 = tf.keras.layers.UpSampling2D((2,2))(upsamp1)\n",
    "\n",
    "pre_trained_model = model(upsamp2)\n",
    "dense41 = tf.keras.layers.Dense(128, activation='relu')(pre_trained_model)\n",
    "x1 = Flatten()(dense41)\n",
    "predictions = tf.keras.layers.Dense(100, activation='softmax')(x1)\n",
    "\n",
    "\n",
    "t_model = Model(inputs = inputs, outputs = predictions)\n",
    "t_model.summary()\n",
    "\n",
    "pre_trained_model2 = model2(upsamp2)\n",
    "dense42 = tf.keras.layers.Dense(128, activation='relu')(pre_trained_model2)\n",
    "x2 = Flatten()(dense42)\n",
    "predictions2 = tf.keras.layers.Dense(100, activation='softmax')(x2)\n",
    "\n",
    "t_model2 = Model(inputs = inputs, outputs = predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "907/907 [==============================] - 112s 105ms/step - loss: 4.1172 - accuracy: 0.1164 - val_loss: 2.2280 - val_accuracy: 0.4357\n",
      "Epoch 2/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 1.9399 - accuracy: 0.5313 - val_loss: 1.0346 - val_accuracy: 0.7670\n",
      "Epoch 3/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.9493 - accuracy: 0.7839 - val_loss: 0.5481 - val_accuracy: 0.8852\n",
      "Epoch 4/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.5472 - accuracy: 0.8759 - val_loss: 0.3470 - val_accuracy: 0.9228\n",
      "Epoch 5/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.3682 - accuracy: 0.9162 - val_loss: 0.2491 - val_accuracy: 0.9441\n",
      "Epoch 6/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.2695 - accuracy: 0.9371 - val_loss: 0.1947 - val_accuracy: 0.9543\n",
      "Epoch 7/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.2189 - accuracy: 0.9476 - val_loss: 0.1618 - val_accuracy: 0.9612\n",
      "Epoch 8/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.1822 - accuracy: 0.9554 - val_loss: 0.1403 - val_accuracy: 0.9650\n",
      "Epoch 9/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.1591 - accuracy: 0.9599 - val_loss: 0.1236 - val_accuracy: 0.9687\n",
      "Epoch 10/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.1358 - accuracy: 0.9654 - val_loss: 0.1122 - val_accuracy: 0.9703\n",
      "Epoch 11/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1230 - accuracy: 0.9686 - val_loss: 0.1040 - val_accuracy: 0.9730\n",
      "Epoch 12/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1085 - accuracy: 0.9722 - val_loss: 0.0973 - val_accuracy: 0.9743\n",
      "Epoch 13/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1033 - accuracy: 0.9725 - val_loss: 0.0910 - val_accuracy: 0.9762\n",
      "Epoch 14/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0940 - accuracy: 0.9755 - val_loss: 0.0852 - val_accuracy: 0.9772\n",
      "Epoch 15/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0863 - accuracy: 0.9774 - val_loss: 0.0823 - val_accuracy: 0.9779\n",
      "Epoch 16/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0834 - accuracy: 0.9785 - val_loss: 0.0795 - val_accuracy: 0.9784\n",
      "Epoch 17/50\n",
      "182/907 [=====>........................] - ETA: 1:11 - loss: 0.0778 - accuracy: 0.9798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0643 - accuracy: 0.9825 - val_loss: 0.0702 - val_accuracy: 0.9804\n",
      "Epoch 20/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0621 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9807\n",
      "Epoch 21/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0596 - accuracy: 0.9842 - val_loss: 0.0667 - val_accuracy: 0.9815\n",
      "Epoch 22/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0510 - accuracy: 0.9862 - val_loss: 0.0632 - val_accuracy: 0.9814\n",
      "Epoch 24/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0508 - accuracy: 0.9870 - val_loss: 0.0621 - val_accuracy: 0.9819\n",
      "Epoch 25/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.0535 - val_accuracy: 0.9845\n",
      "Epoch 32/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.0536 - val_accuracy: 0.9849\n",
      "Epoch 33/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.0529 - val_accuracy: 0.9849\n",
      "Epoch 34/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.0519 - val_accuracy: 0.9854\n",
      "Epoch 35/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0518 - val_accuracy: 0.9854\n",
      "Epoch 36/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0312 - accuracy: 0.9914 - val_loss: 0.0518 - val_accuracy: 0.9849\n",
      "Epoch 37/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0324 - accuracy: 0.9911 - val_loss: 0.0504 - val_accuracy: 0.9852\n",
      "Epoch 38/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0308 - accuracy: 0.9914 - val_loss: 0.0502 - val_accuracy: 0.9848\n",
      "Epoch 39/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.0487 - val_accuracy: 0.9854\n",
      "Epoch 40/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0272 - accuracy: 0.9925 - val_loss: 0.0490 - val_accuracy: 0.9853\n",
      "Epoch 41/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.0480 - val_accuracy: 0.9855\n",
      "Epoch 42/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.0257 - accuracy: 0.9934 - val_loss: 0.0483 - val_accuracy: 0.9862\n",
      "Epoch 43/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.0478 - val_accuracy: 0.9861\n",
      "Epoch 44/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0477 - val_accuracy: 0.9857\n",
      "Epoch 45/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.0469 - val_accuracy: 0.9861\n",
      "Epoch 46/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0469 - val_accuracy: 0.9855\n",
      "Epoch 47/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0473 - val_accuracy: 0.9863\n",
      "Epoch 48/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.0467 - val_accuracy: 0.9864\n",
      "Epoch 49/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.0457 - val_accuracy: 0.9861\n",
      "Epoch 50/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 0.0454 - val_accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "t_model.compile(optimizer=optimizers.SGD(lr=1e-5,momentum=0.9), loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "history = t_model.fit(x_train, y_train, batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=50, verbose=1)\n",
    "\n",
    "#for model2\n",
    "###t_model2.compile(optimizer=optimizers.SGD(lr=1e-5,momentum=0.9), loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "##history2 = t_model2.fit(x_train, y_train, batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "907/907 [==============================] - 101s 105ms/step - loss: 4.2004 - accuracy: 0.0948 - val_loss: 2.4361 - val_accuracy: 0.4147\n",
      "Epoch 2/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 2.0058 - accuracy: 0.5126 - val_loss: 1.0676 - val_accuracy: 0.7576\n",
      "Epoch 3/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.9507 - accuracy: 0.7825 - val_loss: 0.5677 - val_accuracy: 0.8755\n",
      "Epoch 4/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.5521 - accuracy: 0.8739 - val_loss: 0.3529 - val_accuracy: 0.9210\n",
      "Epoch 5/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.3763 - accuracy: 0.9110 - val_loss: 0.2533 - val_accuracy: 0.9399\n",
      "Epoch 6/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.2842 - accuracy: 0.9323 - val_loss: 0.2003 - val_accuracy: 0.9494\n",
      "Epoch 7/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.2287 - accuracy: 0.9434 - val_loss: 0.1628 - val_accuracy: 0.9588\n",
      "Epoch 8/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1900 - accuracy: 0.9520 - val_loss: 0.1406 - val_accuracy: 0.9637\n",
      "Epoch 9/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1649 - accuracy: 0.9561 - val_loss: 0.1267 - val_accuracy: 0.9653\n",
      "Epoch 10/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1480 - accuracy: 0.9610 - val_loss: 0.1123 - val_accuracy: 0.9700\n",
      "Epoch 11/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1315 - accuracy: 0.9659 - val_loss: 0.1035 - val_accuracy: 0.9710\n",
      "Epoch 12/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1193 - accuracy: 0.9689 - val_loss: 0.0950 - val_accuracy: 0.9731\n",
      "Epoch 13/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.1073 - accuracy: 0.9718 - val_loss: 0.0898 - val_accuracy: 0.9747\n",
      "Epoch 14/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0989 - accuracy: 0.9731 - val_loss: 0.0845 - val_accuracy: 0.9762\n",
      "Epoch 15/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.0904 - accuracy: 0.9765 - val_loss: 0.0790 - val_accuracy: 0.9776\n",
      "Epoch 16/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0854 - accuracy: 0.9777 - val_loss: 0.0752 - val_accuracy: 0.9780\n",
      "Epoch 17/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0818 - accuracy: 0.9775 - val_loss: 0.0725 - val_accuracy: 0.9783\n",
      "Epoch 18/50\n",
      "907/907 [==============================] - 93s 103ms/step - loss: 0.0801 - accuracy: 0.9774 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
      "Epoch 19/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0726 - accuracy: 0.9798 - val_loss: 0.0678 - val_accuracy: 0.9801\n",
      "Epoch 20/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0670 - accuracy: 0.9816 - val_loss: 0.0659 - val_accuracy: 0.9801\n",
      "Epoch 21/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0646 - accuracy: 0.9830 - val_loss: 0.0643 - val_accuracy: 0.9805\n",
      "Epoch 22/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0625 - accuracy: 0.9828 - val_loss: 0.0629 - val_accuracy: 0.9807\n",
      "Epoch 23/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0594 - accuracy: 0.9831 - val_loss: 0.0609 - val_accuracy: 0.9814\n",
      "Epoch 24/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0570 - accuracy: 0.9837 - val_loss: 0.0588 - val_accuracy: 0.9821\n",
      "Epoch 25/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0506 - accuracy: 0.9861 - val_loss: 0.0578 - val_accuracy: 0.9820\n",
      "Epoch 26/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0513 - accuracy: 0.9860 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
      "Epoch 27/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0488 - accuracy: 0.9866 - val_loss: 0.0552 - val_accuracy: 0.9824\n",
      "Epoch 28/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0486 - accuracy: 0.9856 - val_loss: 0.0543 - val_accuracy: 0.9832\n",
      "Epoch 29/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0461 - accuracy: 0.9876 - val_loss: 0.0535 - val_accuracy: 0.9839\n",
      "Epoch 30/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0443 - accuracy: 0.9879 - val_loss: 0.0526 - val_accuracy: 0.9843\n",
      "Epoch 31/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0437 - accuracy: 0.9883 - val_loss: 0.0521 - val_accuracy: 0.9841\n",
      "Epoch 32/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0409 - accuracy: 0.9883 - val_loss: 0.0508 - val_accuracy: 0.9848\n",
      "Epoch 33/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0400 - accuracy: 0.9891 - val_loss: 0.0510 - val_accuracy: 0.9849\n",
      "Epoch 34/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0367 - accuracy: 0.9905 - val_loss: 0.0492 - val_accuracy: 0.9851\n",
      "Epoch 35/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 0.0489 - val_accuracy: 0.9848\n",
      "Epoch 36/50\n",
      "907/907 [==============================] - 95s 104ms/step - loss: 0.0369 - accuracy: 0.9898 - val_loss: 0.0481 - val_accuracy: 0.9857\n",
      "Epoch 37/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.0350 - accuracy: 0.9900 - val_loss: 0.0474 - val_accuracy: 0.9853\n",
      "Epoch 38/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0324 - accuracy: 0.9919 - val_loss: 0.0469 - val_accuracy: 0.9861\n",
      "Epoch 39/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0329 - accuracy: 0.9914 - val_loss: 0.0472 - val_accuracy: 0.9857\n",
      "Epoch 40/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0315 - accuracy: 0.9914 - val_loss: 0.0472 - val_accuracy: 0.9854\n",
      "Epoch 41/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.0288 - accuracy: 0.9925 - val_loss: 0.0462 - val_accuracy: 0.9859\n",
      "Epoch 42/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
      "Epoch 43/50\n",
      "907/907 [==============================] - 94s 104ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0457 - val_accuracy: 0.9860\n",
      "Epoch 44/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.0455 - val_accuracy: 0.9864\n",
      "Epoch 45/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.0450 - val_accuracy: 0.9866\n",
      "Epoch 46/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 0.0442 - val_accuracy: 0.9865\n",
      "Epoch 47/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.0444 - val_accuracy: 0.9867\n",
      "Epoch 48/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.0441 - val_accuracy: 0.9871\n",
      "Epoch 49/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0432 - val_accuracy: 0.9872\n",
      "Epoch 50/50\n",
      "907/907 [==============================] - 94s 103ms/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.0429 - val_accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "t_model2.compile(optimizer=optimizers.SGD(lr=1e-5,momentum=0.9), loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "history2 = t_model2.fit(x_train, y_train, batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history2.history['accuracy'], color='m')\n",
    "plt.plot(history2.history['val_accuracy'], color='g')\n",
    "#plt.title('Positive Cosine Similarity Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['high_cos_train', 'high_cos_val','low_cos_train','low_cos_val'], loc='lower right')\n",
    "#plt.savefig('cosine_sim.svg', format='svg', dpi=600) \n",
    "#plt.savefig('cosine_sim.eps', format='eps', dpi=600) \n",
    "#plt.legend(['high_cos_train', 'high_cos_val','low_cos_train','low_cos_val'], loc=\"center right\", bbox_to_anchor=(1.6, 0.5))\n",
    "fig1.savefig('positive_cosine_similarity_mnist_inception.eps', dpi=1000, format=\"eps\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "#fig2 = plt.figure()\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.plot(history2.history['loss'])\n",
    "#plt.plot(history2.history['val_loss'])\n",
    "#plt.title('Positive Negative Cosine Similarity Model Loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['high_cos_train', 'high_cos_val','low_cos_train','low_cos_val'], loc='upper right')\n",
    "#fig2.savefig('cosine_Loss.png', format='png', dpi=600)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
