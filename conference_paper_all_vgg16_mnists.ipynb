{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SciPy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from SciPy) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import statistics as stats\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 as resnet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 as inception\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 as vgg16\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 as densenet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, losses, optimizers\n",
    "from tensorflow.keras.layers import Dense,Dropout,GlobalAveragePooling2D,Flatten\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tensorflow.keras.datasets.fashion_mnist.load_data()\n",
    "#similar to mnist\n",
    "#(x_train, y_train), (x_test, y_test)=tensorflow.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tensorflow.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n",
    "x_test = tensorflow.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n",
    "x_train = tensorflow.expand_dims(x_train, axis=3, name=None)\n",
    "x_test = tensorflow.expand_dims(x_test, axis=3, name=None)\n",
    "x_train = tensorflow.repeat(x_train, 3, axis=3)\n",
    "x_test = tensorflow.repeat(x_test, 3, axis=3)\n",
    "x_val = x_train[-2000:,:,:]\n",
    "y_val = y_train[-2000:]\n",
    "x_train = x_train[:-2000,:,:]\n",
    "y_train = y_train[:-2000]\n",
    "\n",
    "y_train = tensorflow.one_hot(y_train.astype(np.int32), depth=100)\n",
    "y_test = tensorflow.one_hot(y_test.astype(np.int32), depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = vgg16\n",
    "input_t =(32,32, 3)\n",
    "model = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "\n",
    "model2 = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "\n",
    "model3 = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "model_tune1 = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "model_tune2 = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "model_tune3 = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)\n",
    "model_tune4 = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_shape=input_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the layer index\n",
    "def getLayerIndex(model_i, layer_name):\n",
    "    for pos, layer_g in enumerate(model_i.layers):\n",
    "        if layer_g.name == layer_name:\n",
    "            return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# get the convolved layers into an array for looping\n",
    "convolved_layers = []\n",
    "\n",
    "for layer in model.layers:\n",
    "\n",
    "    t = np.array(layer.get_weights()).ndim\n",
    "    array = np.array(layer.get_weights())\n",
    "    if (model_name != resnet50) or (model_name != vgg16):\n",
    "        if (len(array) > 0) and (t > 2):\n",
    "            index = getLayerIndex(model, layer.name)\n",
    "            # append the convolved layer\n",
    "            convolved_layers.append(index)\n",
    "            # print(str(len(array)) + \"for:\" + layer.name + \"at index:\" + str(index))\n",
    "    if (model_name == resnet50) or (model_name == vgg16):\n",
    "        if len(array) > 0 and (t != 2):\n",
    "            index = getLayerIndex(model, layer.name)\n",
    "            # append the convolved layer\n",
    "            convolved_layers.append(index)\n",
    "            # print(str(len(array)) + \"for:\" + layer.name + \"at index:\" + str(index))\n",
    "\n",
    "# get the total number of weights in the array\n",
    "total_layer_weights = 0\n",
    "sum_positives = 0\n",
    "sum_negatives = 0\n",
    "\n",
    "# create a dictionary with layer index and positive values identified\n",
    "layer_positives_dict = defaultdict(list)\n",
    "\n",
    "# create a dictionary for storing the layers and their +ve values probabilities\n",
    "layer_probs_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# list the convolved layers\n",
    "for c_layer in range(len(convolved_layers)):\n",
    "    # create array for array matrices,feature values and convolved values for each layer\n",
    "    layer_array_matrices = []\n",
    "    layer_feature_sums = []\n",
    "    layer_convolved_values_sum = []\n",
    "\n",
    "    # get the arrays matrices(batches) pixel\n",
    "    for i in range(len(model.layers[convolved_layers[c_layer]].get_weights()[0])):\n",
    "        # get the values for each feature\n",
    "        ######print(\"channels(image):\"+str(len(model.layers[convolved_layers[c_layer]].get_weights()[0][i])))\n",
    "        for x in range(len(model.layers[convolved_layers[c_layer]].get_weights()[0][i])):\n",
    "            # return all the values in the convolutional feature\n",
    "            total_array = np.array(model.layers[convolved_layers[c_layer]].get_weights()[0][i][x])\n",
    "            # return all the negative values in the convolutional feature\n",
    "            x2 = np.array(model.layers[convolved_layers[c_layer]].get_weights()[0][i][x]) < 0\n",
    "            for c in range(len(x2)):\n",
    "                ###print(\"all the trues in depth: \" + str(c + 1) + \" are for feature: \" + str(x + 1))\n",
    "                sum_negatives += sum(x2[c])\n",
    "                # print(sum(x2[c]))\n",
    "            # return all the values\n",
    "            for y in range(len(total_array)):\n",
    "                total_layer_weights += len(total_array[y])\n",
    "\n",
    "            x1 = np.array(model.layers[convolved_layers[c_layer]].get_weights()[0][i][x]) > 0\n",
    "            # get the values for each channel\n",
    "            for a in range(len(x1)):\n",
    "                value_pix = sum(x1[a])\n",
    "                # get the positive values\n",
    "                sum_positives += value_pix\n",
    "\n",
    "                ######print(value_pix)\n",
    "    list_sums = []\n",
    "    list_sums.append((str(convolved_layers[c_layer]), sum_positives))\n",
    "    layer_positives_dict.update(list_sums)\n",
    "\n",
    "    # print the probabilities for each layer\n",
    "    layer_pos_prob = sum_positives / total_layer_weights\n",
    "\n",
    "    # create +ves values array\n",
    "    positives_array = []\n",
    "    for key, val in layer_positives_dict.items():\n",
    "        # print(key, \"corresponds to:\",val,\" positive values\")\n",
    "        positives_array.append(val)\n",
    "       \n",
    "    list_layer_probs = []\n",
    "    list_layer_probs.append((str(convolved_layers[c_layer]), layer_pos_prob))\n",
    "    layer_probs_dict.update(list_layer_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_layer = stats.median(convolved_layers)\n",
    "\n",
    "# create dictionary for storing selected median layers\n",
    "second_layer_probs_dict = defaultdict(list)\n",
    "# store the new list of layers to be matched with the mean probability\n",
    "second_half_layers = []\n",
    "\n",
    "# store all probabilities for the selected upper half layers\n",
    "second_half_probs = []\n",
    "# loop through the layers and print those layers above the median\n",
    "for lyr, val in layer_probs_dict.items():\n",
    "    # print(lyr, \"Layer prob:\", val)\n",
    "    if int(lyr) > median_layer:\n",
    "        # store the probabilities of the upper half selected convolved layers\n",
    "        #print(lyr, \"Layer prob:\", val)\n",
    "        # update the sum of selected layers probabilities\n",
    "        second_half_probs.append(val)\n",
    "        second_half_layers.append((lyr, val))\n",
    "        second_layer_probs_dict.update(second_half_layers)\n",
    "\n",
    "# get the mean of the layers\n",
    "selected_layers_mean = stats.mean(second_half_probs)\n",
    "final_selected_layers = []\n",
    "# now get the final layers list whose value exceed the mean\n",
    "for s_lyr, v in second_layer_probs_dict.items():\n",
    "    # get the probabilities that are lower than the mean probability\n",
    "    if v < selected_layers_mean:\n",
    "        # store the probabilities of the upper half selected convolved layers\n",
    "        final_selected_layers.append(s_lyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 True\n",
      "block4_conv2 True\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n",
      "block5_pool True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for positive cosines similarities\n",
    "pcs_h_layers =[1,12,15,16]\n",
    "pcs_l_layers =[4,5,7,9] #lower cosine\n",
    "for sb_layer in model.layers:\n",
    "    # sb_layer.trainable = False\n",
    "    index = getLayerIndex(model, sb_layer.name)\n",
    "    #for b in final_selected_layers:\n",
    "    for b in pcs_h_layers:\n",
    "        if b == index:\n",
    "            sb_layer.trainable = True\n",
    "            #print(str(sb_layer.name) + \" and index is\" + str(b))\n",
    "            print(sb_layer.name,sb_layer.trainable)\n",
    "\n",
    "#for negative cosine similarities\n",
    "# for model 2\n",
    "# for positive cosines similarities\n",
    "ncs_h_layers =[1,12,13,15,16]\n",
    "ncs_l_layers =[4,5,7,8]\n",
    "for sbs_layer in model2.layers:\n",
    "    # sb_layer.trainable = False\n",
    "    index = getLayerIndex(model2, sbs_layer.name)\n",
    "    #for b in final_selected_layers:\n",
    "    for b in ncs_h_layers:\n",
    "        if b == index:\n",
    "            sb_layer.trainable = True\n",
    "            #print(str(sb_layer.name) + \" and index is\" + str(b))\n",
    "            print(sb_layer.name,sb_layer.trainable)\n",
    "\n",
    "#for positive negative cosine similarities\n",
    "# for model 3\n",
    "pncs_h_layers =[1,4,5,12,13] #high cosine,,\n",
    "pncs_l_layers =[7,9,15,16] #lower cosine\n",
    "for sbs_layer in model3.layers:\n",
    "    # sb_layer.trainable = False\n",
    "    index = getLayerIndex(model3, sbs_layer.name)\n",
    "    #for b in final_selected_layers:\n",
    "    for b in pncs_h_layers:\n",
    "        if b == index:\n",
    "            sb_layer.trainable = True\n",
    "            #print(str(sb_layer.name) + \" and index is\" + str(b))\n",
    "            print(sb_layer.name,sb_layer.trainable)\n",
    "\n",
    "\n",
    "#finetune by removeing the last layer\n",
    "for lst_layer in model_tune1.layers[:-2]:\n",
    "    lst_layer.trainable = False\n",
    "    \n",
    "####end of the last layer\n",
    "#finetune by removeing the 2nd last layer\n",
    "for scnd_st_layer in model_tune2.layers[:-3]:\n",
    "    scnd_st_layer.trainable = False\n",
    "    \n",
    "####end of the last layer\n",
    "#finetune by removeing the 3rd last layer\n",
    "for thrd_layer in model_tune3.layers[:-4]:\n",
    "    thrd_layer.trainable = False\n",
    "    \n",
    "\n",
    "    \n",
    "####end of the last layer\n",
    "#for feature extraction\n",
    "for ftr_layer in model_tune4.layers:\n",
    "    ftr_layer.trainable = False\n",
    "\n",
    "# try the transfer learning model\n",
    "to_res = (224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_model = Sequential()\n",
    "t_model.add(model)\n",
    "t_model.add(Flatten())\n",
    "t_model.add(layers.BatchNormalization())\n",
    "t_model.add(layers.Dense(64, activation='relu'))\n",
    "t_model.add(layers.Dropout(0.5))\n",
    "t_model.add(layers.BatchNormalization())\n",
    "t_model.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "\n",
    "#for model 2\n",
    "t_model2 = Sequential()\n",
    "t_model2.add(model2)\n",
    "t_model2.add(Flatten())\n",
    "t_model2.add(layers.BatchNormalization())\n",
    "t_model2.add(layers.Dense(64, activation='relu'))\n",
    "t_model2.add(layers.Dropout(0.5))\n",
    "t_model2.add(layers.BatchNormalization())\n",
    "t_model2.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "\n",
    "#for model 2\n",
    "t_model3 = Sequential()\n",
    "t_model3.add(model3)\n",
    "t_model3.add(Flatten())\n",
    "t_model3.add(layers.BatchNormalization())\n",
    "t_model3.add(layers.Dense(64, activation='relu'))\n",
    "t_model3.add(layers.Dropout(0.5))\n",
    "t_model3.add(layers.BatchNormalization())\n",
    "t_model3.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "\n",
    "#for model 2\n",
    "t_model4 = Sequential()\n",
    "t_model4.add(model_tune1)\n",
    "t_model4.add(Flatten())\n",
    "t_model4.add(layers.BatchNormalization())\n",
    "t_model4.add(layers.Dense(64, activation='relu'))\n",
    "t_model4.add(layers.Dropout(0.5))\n",
    "t_model4.add(layers.BatchNormalization())\n",
    "t_model4.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "#for model 2\n",
    "t_model5 = Sequential()\n",
    "t_model5.add(model_tune2)\n",
    "t_model5.add(Flatten())\n",
    "t_model5.add(layers.BatchNormalization())\n",
    "t_model5.add(layers.Dense(64, activation='relu'))\n",
    "t_model5.add(layers.Dropout(0.5))\n",
    "t_model5.add(layers.BatchNormalization())\n",
    "t_model5.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "#for model 2\n",
    "t_model6 = Sequential()\n",
    "t_model6.add(model_tune3)\n",
    "t_model6.add(Flatten())\n",
    "t_model6.add(layers.BatchNormalization())\n",
    "t_model6.add(layers.Dense(64, activation='relu'))\n",
    "t_model6.add(layers.Dropout(0.5))\n",
    "t_model6.add(layers.BatchNormalization())\n",
    "t_model6.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "\n",
    "#for model 2\n",
    "t_model7 = Sequential()\n",
    "t_model7.add(model_tune3)\n",
    "t_model7.add(Flatten())\n",
    "t_model7.add(layers.BatchNormalization())\n",
    "t_model7.add(layers.Dense(64, activation='relu'))\n",
    "t_model7.add(layers.Dropout(0.5))\n",
    "t_model7.add(layers.BatchNormalization())\n",
    "t_model7.add(layers.Dense(100, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "907/907 [==============================] - 36s 36ms/step - loss: 4.1171 - accuracy: 0.1525 - val_loss: 2.5003 - val_accuracy: 0.7704\n",
      "Epoch 2/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.6946 - accuracy: 0.6295 - val_loss: 2.1068 - val_accuracy: 0.8089\n",
      "Epoch 3/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.3482 - accuracy: 0.7338 - val_loss: 1.8836 - val_accuracy: 0.8285\n",
      "Epoch 4/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.1405 - accuracy: 0.7799 - val_loss: 1.7160 - val_accuracy: 0.8418\n",
      "Epoch 5/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.9798 - accuracy: 0.8110 - val_loss: 1.5839 - val_accuracy: 0.8494\n",
      "Epoch 6/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.8597 - accuracy: 0.8253 - val_loss: 1.5078 - val_accuracy: 0.8579\n",
      "Epoch 7/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.7458 - accuracy: 0.8378 - val_loss: 1.3598 - val_accuracy: 0.8608\n",
      "Epoch 8/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.6449 - accuracy: 0.8460 - val_loss: 1.3015 - val_accuracy: 0.8684\n",
      "Epoch 9/20\n",
      "907/907 [==============================] - 32s 36ms/step - loss: 1.5660 - accuracy: 0.8521 - val_loss: 1.2194 - val_accuracy: 0.8735\n",
      "Epoch 10/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.4693 - accuracy: 0.8621 - val_loss: 1.1474 - val_accuracy: 0.8748\n",
      "Epoch 11/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.4057 - accuracy: 0.8659 - val_loss: 1.0588 - val_accuracy: 0.8793\n",
      "Epoch 12/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.3334 - accuracy: 0.8740 - val_loss: 1.0255 - val_accuracy: 0.8827\n",
      "Epoch 13/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.2783 - accuracy: 0.8725 - val_loss: 0.9327 - val_accuracy: 0.8855\n",
      "Epoch 14/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.2298 - accuracy: 0.8761 - val_loss: 0.8947 - val_accuracy: 0.8873\n",
      "Epoch 15/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.1667 - accuracy: 0.8803 - val_loss: 0.8567 - val_accuracy: 0.8907\n",
      "Epoch 16/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.1204 - accuracy: 0.8829 - val_loss: 0.8029 - val_accuracy: 0.8873 - ETA: 2s - loss: 1.1214 - accura - ETA: 1s - loss: 1.1213 - \n",
      "Epoch 17/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.0699 - accuracy: 0.8867 - val_loss: 0.7705 - val_accuracy: 0.8921\n",
      "Epoch 18/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.0298 - accuracy: 0.8894 - val_loss: 0.7457 - val_accuracy: 0.8943\n",
      "Epoch 19/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 0.9954 - accuracy: 0.8924 - val_loss: 0.7106 - val_accuracy: 0.8951\n",
      "Epoch 20/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 0.9586 - accuracy: 0.8927 - val_loss: 0.6851 - val_accuracy: 0.8947\n"
     ]
    }
   ],
   "source": [
    "#positive cosine similarity\n",
    "t_model.compile(loss=losses.CategoricalCrossentropy(from_logits=True),optimizer=optimizers.SGD(lr=1e-5,momentum=0.9),metrics=['accuracy'])\n",
    "history = t_model.fit(x_train, y_train, batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "907/907 [==============================] - 33s 35ms/step - loss: 4.0178 - accuracy: 0.1788 - val_loss: 2.4985 - val_accuracy: 0.7679\n",
      "Epoch 2/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.6359 - accuracy: 0.6290 - val_loss: 2.0810 - val_accuracy: 0.8104\n",
      "Epoch 3/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.3172 - accuracy: 0.7250 - val_loss: 1.8881 - val_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.1247 - accuracy: 0.7746 - val_loss: 1.7298 - val_accuracy: 0.8444\n",
      "Epoch 5/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.9780 - accuracy: 0.8019 - val_loss: 1.6159 - val_accuracy: 0.8545 1.9782 - accuracy\n",
      "Epoch 6/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.8606 - accuracy: 0.8202 - val_loss: 1.5141 - val_accuracy: 0.8579\n",
      "Epoch 7/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.7584 - accuracy: 0.8336 - val_loss: 1.4061 - val_accuracy: 0.8662\n",
      "Epoch 8/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.6622 - accuracy: 0.8441 - val_loss: 1.3166 - val_accuracy: 0.8698\n",
      "Epoch 9/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.5623 - accuracy: 0.8562 - val_loss: 1.2417 - val_accuracy: 0.8722\n",
      "Epoch 10/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.4907 - accuracy: 0.8586 - val_loss: 1.1596 - val_accuracy: 0.8752\n",
      "Epoch 11/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.4211 - accuracy: 0.8673 - val_loss: 1.1161 - val_accuracy: 0.8761\n",
      "Epoch 12/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.3547 - accuracy: 0.8701 - val_loss: 1.0358 - val_accuracy: 0.8827\n",
      "Epoch 13/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.2935 - accuracy: 0.8734 - val_loss: 0.9925 - val_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.2397 - accuracy: 0.8780 - val_loss: 0.9402 - val_accuracy: 0.8856\n",
      "Epoch 15/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.1859 - accuracy: 0.8824 - val_loss: 0.8900 - val_accuracy: 0.8865oss: 1.1861 - accuracy: 0.88 - ETA: 0s - loss: 1.1861 \n",
      "Epoch 16/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.1402 - accuracy: 0.8825 - val_loss: 0.8490 - val_accuracy: 0.8903\n",
      "Epoch 17/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.0911 - accuracy: 0.8856 - val_loss: 0.8022 - val_accuracy: 0.8927\n",
      "Epoch 18/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.0504 - accuracy: 0.8884 - val_loss: 0.7850 - val_accuracy: 0.8929\n",
      "Epoch 19/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.0197 - accuracy: 0.8897 - val_loss: 0.7609 - val_accuracy: 0.8923\n",
      "Epoch 20/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 0.9752 - accuracy: 0.8921 - val_loss: 0.7120 - val_accuracy: 0.8968\n"
     ]
    }
   ],
   "source": [
    "#negative cosine similarity look\n",
    "#for model2\n",
    "t_model2.compile(loss=losses.CategoricalCrossentropy(from_logits=True),optimizer=optimizers.SGD(lr=1e-5,momentum=0.9),metrics=['accuracy'])\n",
    "history2 = t_model2.fit(x_train, y_train,  batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "907/907 [==============================] - 33s 36ms/step - loss: 4.0498 - accuracy: 0.1626 - val_loss: 2.6453 - val_accuracy: 0.7378\n",
      "Epoch 2/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.8208 - accuracy: 0.5835 - val_loss: 2.2533 - val_accuracy: 0.7968\n",
      "Epoch 3/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.4725 - accuracy: 0.7005 - val_loss: 2.0175 - val_accuracy: 0.8243\n",
      "Epoch 4/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.2750 - accuracy: 0.7544 - val_loss: 1.8881 - val_accuracy: 0.8395\n",
      "Epoch 5/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 2.1238 - accuracy: 0.7851 - val_loss: 1.7355 - val_accuracy: 0.8496\n",
      "Epoch 6/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.9781 - accuracy: 0.8110 - val_loss: 1.6156 - val_accuracy: 0.8588\n",
      "Epoch 7/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.8725 - accuracy: 0.8259 - val_loss: 1.5006 - val_accuracy: 0.8623\n",
      "Epoch 8/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.7675 - accuracy: 0.8383 - val_loss: 1.3980 - val_accuracy: 0.8672\n",
      "Epoch 9/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.6729 - accuracy: 0.8506 - val_loss: 1.3206 - val_accuracy: 0.8725\n",
      "Epoch 10/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.5968 - accuracy: 0.8571 - val_loss: 1.2500 - val_accuracy: 0.8734\n",
      "Epoch 11/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.5081 - accuracy: 0.8666 - val_loss: 1.1961 - val_accuracy: 0.8813\n",
      "Epoch 12/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.4585 - accuracy: 0.8659 - val_loss: 1.1257 - val_accuracy: 0.8818\n",
      "Epoch 13/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.3909 - accuracy: 0.8725 - val_loss: 1.0575 - val_accuracy: 0.8852\n",
      "Epoch 14/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.3209 - accuracy: 0.8788 - val_loss: 1.0036 - val_accuracy: 0.8850\n",
      "Epoch 15/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.2617 - accuracy: 0.8822 - val_loss: 0.9606 - val_accuracy: 0.8886\n",
      "Epoch 16/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.2116 - accuracy: 0.8849 - val_loss: 0.9235 - val_accuracy: 0.8886\n",
      "Epoch 17/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.1709 - accuracy: 0.8863 - val_loss: 0.8592 - val_accuracy: 0.8940\n",
      "Epoch 18/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.1305 - accuracy: 0.8866 - val_loss: 0.8422 - val_accuracy: 0.8942\n",
      "Epoch 19/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.0849 - accuracy: 0.8911 - val_loss: 0.7905 - val_accuracy: 0.8947\n",
      "Epoch 20/20\n",
      "907/907 [==============================] - 32s 35ms/step - loss: 1.0480 - accuracy: 0.8921 - val_loss: 0.7656 - val_accuracy: 0.8980\n"
     ]
    }
   ],
   "source": [
    "#for model3\n",
    "t_model3.compile(loss=losses.CategoricalCrossentropy(from_logits=True),optimizer=optimizers.SGD(lr=1e-5,momentum=0.9),metrics=['accuracy'])\n",
    "history3 = t_model3.fit(x_train, y_train,  batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "907/907 [==============================] - 14s 14ms/step - loss: 4.4276 - accuracy: 0.0692 - val_loss: 3.2165 - val_accuracy: 0.5464\n",
      "Epoch 2/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 3.3618 - accuracy: 0.3462 - val_loss: 2.7861 - val_accuracy: 0.6621\n",
      "Epoch 3/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.9980 - accuracy: 0.4811 - val_loss: 2.5326 - val_accuracy: 0.7071\n",
      "Epoch 4/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.7608 - accuracy: 0.5636 - val_loss: 2.3303 - val_accuracy: 0.7370\n",
      "Epoch 5/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.5828 - accuracy: 0.6169 - val_loss: 2.1718 - val_accuracy: 0.7557\n",
      "Epoch 6/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.4407 - accuracy: 0.6509 - val_loss: 2.0356 - val_accuracy: 0.7677\n",
      "Epoch 7/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.3097 - accuracy: 0.6807 - val_loss: 1.9163 - val_accuracy: 0.7766\n",
      "Epoch 8/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.2162 - accuracy: 0.7004 - val_loss: 1.8228 - val_accuracy: 0.7839\n",
      "Epoch 9/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.1024 - accuracy: 0.7199 - val_loss: 1.7278 - val_accuracy: 0.7925\n",
      "Epoch 10/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 2.0184 - accuracy: 0.7339 - val_loss: 1.6501 - val_accuracy: 0.7980\n",
      "Epoch 11/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.9363 - accuracy: 0.7428 - val_loss: 1.5726 - val_accuracy: 0.8027\n",
      "Epoch 12/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.8636 - accuracy: 0.7530 - val_loss: 1.4980 - val_accuracy: 0.8056\n",
      "Epoch 13/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.7852 - accuracy: 0.7605 - val_loss: 1.4340 - val_accuracy: 0.8076\n",
      "Epoch 14/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.7269 - accuracy: 0.7668 - val_loss: 1.3694 - val_accuracy: 0.8111\n",
      "Epoch 15/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.6737 - accuracy: 0.7712 - val_loss: 1.3135 - val_accuracy: 0.8146\n",
      "Epoch 16/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.6153 - accuracy: 0.7756 - val_loss: 1.2627 - val_accuracy: 0.8159\n",
      "Epoch 17/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.5560 - accuracy: 0.7833 - val_loss: 1.2085 - val_accuracy: 0.8183\n",
      "Epoch 18/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.4936 - accuracy: 0.7936 - val_loss: 1.1722 - val_accuracy: 0.8205\n",
      "Epoch 19/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.4593 - accuracy: 0.7928 - val_loss: 1.1317 - val_accuracy: 0.8217\n",
      "Epoch 20/20\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 1.4183 - accuracy: 0.7942 - val_loss: 1.0830 - val_accuracy: 0.8241\n"
     ]
    }
   ],
   "source": [
    "#for model3\n",
    "t_model4.compile(loss=losses.CategoricalCrossentropy(from_logits=True),optimizer=optimizers.SGD(lr=1e-5,momentum=0.9),metrics=['accuracy'])\n",
    "history4= t_model4.fit(x_train, y_train,  batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=20, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "907/907 [==============================] - 16s 17ms/step - loss: 4.1165 - accuracy: 0.1434 - val_loss: 2.8787 - val_accuracy: 0.6259\n",
      "Epoch 2/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 3.0589 - accuracy: 0.4636 - val_loss: 2.4813 - val_accuracy: 0.7105\n",
      "Epoch 3/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 2.6972 - accuracy: 0.5854 - val_loss: 2.2414 - val_accuracy: 0.7438\n",
      "Epoch 4/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 2.4855 - accuracy: 0.6469 - val_loss: 2.0705 - val_accuracy: 0.7642\n",
      "Epoch 5/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 2.3102 - accuracy: 0.6898 - val_loss: 1.9276 - val_accuracy: 0.7779\n",
      "Epoch 6/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 2.1845 - accuracy: 0.7168 - val_loss: 1.8085 - val_accuracy: 0.7880\n",
      "Epoch 7/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 2.0793 - accuracy: 0.7348 - val_loss: 1.7027 - val_accuracy: 0.7972\n",
      "Epoch 8/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.9606 - accuracy: 0.7548 - val_loss: 1.6137 - val_accuracy: 0.8026\n",
      "Epoch 9/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.8687 - accuracy: 0.7655 - val_loss: 1.5279 - val_accuracy: 0.8097\n",
      "Epoch 10/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.7951 - accuracy: 0.7734 - val_loss: 1.4474 - val_accuracy: 0.8147\n",
      "Epoch 11/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.7119 - accuracy: 0.7844 - val_loss: 1.3812 - val_accuracy: 0.8184\n",
      "Epoch 12/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.6413 - accuracy: 0.7887 - val_loss: 1.3141 - val_accuracy: 0.8234\n",
      "Epoch 13/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.5869 - accuracy: 0.7944 - val_loss: 1.2614 - val_accuracy: 0.8301\n",
      "Epoch 14/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.5256 - accuracy: 0.8012 - val_loss: 1.2027 - val_accuracy: 0.8323\n",
      "Epoch 15/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.4615 - accuracy: 0.8082 - val_loss: 1.1599 - val_accuracy: 0.8344\n",
      "Epoch 16/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.4136 - accuracy: 0.8118 - val_loss: 1.1097 - val_accuracy: 0.8390\n",
      "Epoch 17/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.3683 - accuracy: 0.8132 - val_loss: 1.0659 - val_accuracy: 0.8410\n",
      "Epoch 18/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.3215 - accuracy: 0.8163 - val_loss: 1.0250 - val_accuracy: 0.8437\n",
      "Epoch 19/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.2796 - accuracy: 0.8190 - val_loss: 0.9833 - val_accuracy: 0.8471\n",
      "Epoch 20/20\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 1.2397 - accuracy: 0.8208 - val_loss: 0.9467 - val_accuracy: 0.8490\n"
     ]
    }
   ],
   "source": [
    "#for model3\n",
    "t_model5.compile(loss=losses.CategoricalCrossentropy(from_logits=True),optimizer=optimizers.SGD(lr=1e-5,momentum=0.9),metrics=['accuracy'])\n",
    "history5 = t_model5.fit(x_train, y_train,  batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "907/907 [==============================] - 19s 20ms/step - loss: 4.0692 - accuracy: 0.1522 - val_loss: 2.7377 - val_accuracy: 0.6653\n",
      "Epoch 2/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.9412 - accuracy: 0.4998 - val_loss: 2.3726 - val_accuracy: 0.7558\n",
      "Epoch 3/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.5999 - accuracy: 0.6216 - val_loss: 2.1496 - val_accuracy: 0.7882\n",
      "Epoch 4/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.3807 - accuracy: 0.6881 - val_loss: 1.9790 - val_accuracy: 0.8023\n",
      "Epoch 5/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.2366 - accuracy: 0.7215 - val_loss: 1.8434 - val_accuracy: 0.8135\n",
      "Epoch 6/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.1016 - accuracy: 0.7513 - val_loss: 1.7240 - val_accuracy: 0.8200\n",
      "Epoch 7/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.9987 - accuracy: 0.7667 - val_loss: 1.6234 - val_accuracy: 0.8270\n",
      "Epoch 8/20\n",
      "907/907 [==============================] - 18s 20ms/step - loss: 1.8851 - accuracy: 0.7864 - val_loss: 1.5282 - val_accuracy: 0.8324\n",
      "Epoch 9/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.7911 - accuracy: 0.7980 - val_loss: 1.4489 - val_accuracy: 0.8374\n",
      "Epoch 10/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.7193 - accuracy: 0.8066 - val_loss: 1.3697 - val_accuracy: 0.8406\n",
      "Epoch 11/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.6399 - accuracy: 0.8135 - val_loss: 1.2962 - val_accuracy: 0.8455\n",
      "Epoch 12/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.5755 - accuracy: 0.8214 - val_loss: 1.2363 - val_accuracy: 0.8491\n",
      "Epoch 13/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.5121 - accuracy: 0.8244 - val_loss: 1.1888 - val_accuracy: 0.8494\n",
      "Epoch 14/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.4597 - accuracy: 0.8272 - val_loss: 1.1323 - val_accuracy: 0.8529\n",
      "Epoch 15/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.4060 - accuracy: 0.8323 - val_loss: 1.0850 - val_accuracy: 0.8544\n",
      "Epoch 16/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.3542 - accuracy: 0.8356 - val_loss: 1.0331 - val_accuracy: 0.8580\n",
      "Epoch 17/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.2992 - accuracy: 0.8405 - val_loss: 0.9974 - val_accuracy: 0.8599\n",
      "Epoch 18/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.2557 - accuracy: 0.8450 - val_loss: 0.9493 - val_accuracy: 0.8632\n",
      "Epoch 19/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.2230 - accuracy: 0.8421 - val_loss: 0.9094 - val_accuracy: 0.8647\n",
      "Epoch 20/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.1815 - accuracy: 0.8483 - val_loss: 0.8945 - val_accuracy: 0.8645\n"
     ]
    }
   ],
   "source": [
    "#for model3\n",
    "t_model6.compile(loss=losses.CategoricalCrossentropy(from_logits=True),optimizer=optimizers.SGD(lr=1e-5,momentum=0.9),metrics=['accuracy'])\n",
    "history6 = t_model6.fit(x_train, y_train,  batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "907/907 [==============================] - 19s 20ms/step - loss: 3.8776 - accuracy: 0.1985 - val_loss: 2.6456 - val_accuracy: 0.7724\n",
      "Epoch 2/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.8092 - accuracy: 0.5842 - val_loss: 2.2472 - val_accuracy: 0.8048\n",
      "Epoch 3/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.4888 - accuracy: 0.6857 - val_loss: 2.0237 - val_accuracy: 0.8210\n",
      "Epoch 4/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.2722 - accuracy: 0.7383 - val_loss: 1.8693 - val_accuracy: 0.8295\n",
      "Epoch 5/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.1245 - accuracy: 0.7635 - val_loss: 1.7296 - val_accuracy: 0.8334\n",
      "Epoch 6/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 2.0048 - accuracy: 0.7846 - val_loss: 1.6261 - val_accuracy: 0.8439\n",
      "Epoch 7/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.8936 - accuracy: 0.7981 - val_loss: 1.5431 - val_accuracy: 0.8462\n",
      "Epoch 8/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.8044 - accuracy: 0.8088 - val_loss: 1.4585 - val_accuracy: 0.8486\n",
      "Epoch 9/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.7195 - accuracy: 0.8178 - val_loss: 1.3466 - val_accuracy: 0.8538\n",
      "Epoch 10/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.6489 - accuracy: 0.8243 - val_loss: 1.2920 - val_accuracy: 0.8568\n",
      "Epoch 11/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.5639 - accuracy: 0.8327 - val_loss: 1.2199 - val_accuracy: 0.8568\n",
      "Epoch 12/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.5093 - accuracy: 0.8342 - val_loss: 1.1704 - val_accuracy: 0.8613\n",
      "Epoch 13/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.4511 - accuracy: 0.8376 - val_loss: 1.1155 - val_accuracy: 0.8630\n",
      "Epoch 14/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.3917 - accuracy: 0.8420 - val_loss: 1.0511 - val_accuracy: 0.8639\n",
      "Epoch 15/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.3381 - accuracy: 0.8454 - val_loss: 1.0189 - val_accuracy: 0.8658\n",
      "Epoch 16/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.2893 - accuracy: 0.8487 - val_loss: 0.9703 - val_accuracy: 0.8655\n",
      "Epoch 17/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.2445 - accuracy: 0.8508 - val_loss: 0.9260 - val_accuracy: 0.8707\n",
      "Epoch 18/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.2060 - accuracy: 0.8557 - val_loss: 0.8803 - val_accuracy: 0.8715\n",
      "Epoch 19/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.1601 - accuracy: 0.8570 - val_loss: 0.8631 - val_accuracy: 0.8736\n",
      "Epoch 20/20\n",
      "907/907 [==============================] - 18s 19ms/step - loss: 1.1379 - accuracy: 0.8564 - val_loss: 0.8231 - val_accuracy: 0.8723\n"
     ]
    }
   ],
   "source": [
    "#for model3\n",
    "t_model7.compile(loss=losses.CategoricalCrossentropy(from_logits=True),optimizer=optimizers.SGD(lr=1e-5,momentum=0.9),metrics=['accuracy'])\n",
    "history7 = t_model7.fit(x_train, y_train,  batch_size=64, shuffle=True,validation_data=(x_test, y_test), epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "#plt.plot(history2.history['val_loss'])\n",
    "plt.plot(history2.history['accuracy'])\n",
    "#plt.plot(history3.history['val_loss'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "#plt.plot(history4.history['val_loss'])\n",
    "plt.plot(history3.history['accuracy'])\n",
    "#plt.plot(history5.history['val_loss'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['PCS_Train','PCS_Val','NCS_Train','NCS_Val','PNCS_Train','PNCS_Val'], loc='lower right')\n",
    "#plt.legend(['high_cos_train', 'high_cos_val','low_cos_train','low_cos_val'], loc=\"center right\", bbox_to_anchor=(1.6, 0.5))\n",
    "#fig1.savefig('3plots_fashion_mnist_vgg16.eps', dpi=1200, format=\"eps\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "#plt.plot(history2.history['val_loss'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "#plt.plot(history3.history['val_loss'])\n",
    "plt.plot(history4.history['val_accuracy'])\n",
    "#plt.plot(history4.history['val_loss'])\n",
    "plt.plot(history5.history['val_accuracy'])\n",
    "#plt.plot(history5.history['val_loss'])\n",
    "plt.plot(history6.history['val_accuracy'])\n",
    "#plt.plot(history6.history['val_loss'])\n",
    "plt.plot(history7.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['PCS','NCS','PNCS','1st_Layer','2nd_Layer','3rd_Layer','Feature_Extraction'], loc='lower right')\n",
    "#plt.legend(['high_cos_train', 'high_cos_val','low_cos_train','low_cos_val'], loc=\"center right\", bbox_to_anchor=(1.6, 0.5))\n",
    "fig2.savefig('mul_fashion_mnist_vgg16.eps', dpi=1200, format=\"eps\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
